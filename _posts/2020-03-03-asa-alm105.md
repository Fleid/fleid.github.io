---
layout: post
title:  "Unit testing an Azure Stream Analytics job - ASA-ALM-105"
date:   2020-03-03 10:00:00 -0700
categories: ALM Azure ASA DevOps
---

# Unit testing an Azure Stream Analytics job

This article is part of a series on enabling modern ALM practices for an Azure Stream Analytics project:

- Part 1 : [100 - The story of 2 pipelines](https://www.eiden.ca/asa-alm-100/)
- Part 2 : [101 - Local developer experience](https://www.eiden.ca/asa-alm-101/)
- Part 3 : [102 - Provisioning scripts and live job](https://www.eiden.ca/asa-alm-102/)
- Part 4 : [103 - Continuous build](https://www.eiden.ca/asa-alm-103/)
- Part 5 : [104 - Automated deployment](https://www.eiden.ca/asa-alm-104/)
- **Part 6** : [105 - Unit testing](https://www.eiden.ca/asa-alm-105/)
- Part 7 : Integration testing - to be written

## Context

Now that we have a [continuous build pipeline](https://www.eiden.ca/asa-alm-103/)) and [automated deployments](https://www.eiden.ca/asa-alm-104/)), we should turn our attention towards **test automation**. These are the 3 practices that will allow us to enable proper CI/CD, a key aspect of DevOps.

To be honest, **we should have started with test automation**, via unit testing, before anything else. In my opinion it is the most important practice of modern ALM. But it took me a [little bit of prep time](https://www.eiden.ca/asa-alm-202002/) to implement automated testing for ASA and write that article.

The main reason being that at the moment, **unit testing is not supported natively for ASA in either VSCode or Visual Studio**. This article will show us how to go around that, using a tool I built and made available on Github: [asa.unittest](https://github.com/Fleid/asa.unittest).

![figure 1 - Test run results](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202001_asa_unittest/ut_prun_terminal.png)

*[figure 1 - Test run results](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202001_asa_unittest/ut_prun_terminal.png)*

It is to be noted that **asa.unittest** is still a [work in progress](https://github.com/Fleid/asa.unittest/projects/1). In consequence I expect this article to be updated regularly in the near future.

## Introduction to asa.unittest

The [github repository](https://github.com/Fleid/asa.unittest) of asa.unittest has a README that gives us some details on what the tool does and how it works.

![figure 2 - asa.unittest internals](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202001_asa_unittest/ut_overview.png)

*[figure 2 - asa.unittest internals](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/202001_asa_unittest/ut_overview.png)*

The short version is that we'll need to prepare a fixture, a fancy term for a folder structure and a couple of config files, for it to run.

But let's not worry to much about how the tool work, and focus on getting it running in our project.

## Requirements and setup

The [requirements](https://github.com/Fleid/asa.unittest#requirements) are fairly standards (PowerShell, Node/NPM, .NET Framework), but make it apparent that **the tool will only work on Windows**. This is due to the limited availability of the `sa.exe` command used under the cover to run the ASA engine programmatically.

Once the requirements are installed, we can download the tool in a zip file from [the repo](https://github.com/Fleid/asa.unittest).

### Solution folder

If it's not already the case, we will need to create a solution folder that will contain both our existing ASA project folder and the new unit test folder. Depending on how version-control was configured, and how the build and release pipelines are setup, this can actually break a lot of things.

Let's try to keep most of the wiring working by:

- Creating a new `ASATest1` folder in our existing `ASATest1` folder
- Moving the ASA content into it : folders (Functions, Inputs, LocalRunOutputs, Outputs) and files (`asaproj.json`, `ASATest1.asaql`, `JobConfig.json`)
- Leaving the other folders untouched (Deploy, Provision) but moving the YAML config file in Deploy (not necessary but why not at this point)
- Adding the `unittest` folder from the zip file in the root folder

On a picture:

![figure 3 - schema of the folder structure reworked](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/201912_asa_alm101/asa_alm105_fs.png)

*[figure 3 - schema of the folder structure reworked](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/201912_asa_alm101/asa_alm105_fs.png)*

We should check that the ASA project is still wired properly (including the `.gitignore` file) by doing a local run in VSCode. We can open at the the solution folder level for that, which will also allow us to [commit and push](https://www.eiden.ca/asa-alm-101/) all of our changes into the Azure DevOps repo.

### Pipelines

We will need to update `Build.ps1` to reflect the change in folder structure. This should be simple, at the top of the file:

```PowerShell
$scriptPath = "$sourceDirectory\$sourceProjectName.asaql"
```

Becomes

```PowerShell
$scriptPath = "$sourceDirectory\$sourceProjectName\$sourceProjectName.asaql"
```

> Note that re-reading that script, I have a strong urge to rewrite it using proper PowerShell. Those hard-coded values... Maybe later...

Then in Azure DevOps, we will need to fix the yaml path of the build pipeline by going in the settings (edit mode, vertical ellipsis top right) and updating the value to `deploy/azure-pipelines.yml`

![figure 4 - Azure DevOps, build pipeline screenshot : fixing the yaml path](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/201912_asa_alm101/asa_alm105_yaml.png)

*[figure 4 - Azure DevOps, build pipeline screenshot : fixing the yaml path](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/201912_asa_alm101/asa_alm105_yaml.png)*

Once fixed, we should trigger a run and check that it's successful, down to the release.

### Unittest

Finally, in the `unittest` folder, we should go in the folder `2_act` and run `Install-AutToolset.ps1`. Then in a PowerShell terminal:

```PowerShell
.\Install-AutToolset.ps1 -solutionPath "C:\Users\fleide\Repos\ASATest1" -verbose
```

As usual, if we get an execution policy warning, we can just `Set-ExecutionPolicy Bypass` to get around it. As a reminder, the VSCode PowerShell integrated console has [a weird behavior](https://github.com/PowerShell/vscode-powershell/issues/1217) around execution policies, so it's best to avoid it and use [another Terminal](https://www.microsoft.com/en-us/p/windows-terminal-preview/9n0dx20hk701?ranMID=24542&ranEAID=TnL5HPStwNw&ranSiteID=TnL5HPStwNw-UDWMLG8.vwB2U4dqg2Flhw&epi=TnL5HPStwNw-UDWMLG8.vwB2U4dqg2Flhw&irgwc=1&OCID=AID681541_aff_7593_1243925&tduid=%28ir__zlyl9dwgqkkfr3dlkk0sohzx0m2xj1uvbfrd6e0v00%29%287593%29%281243925%29%28TnL5HPStwNw-UDWMLG8.vwB2U4dqg2Flhw%29%28%29&irclickid=_zlyl9dwgqkkfr3dlkk0sohzx0m2xj1uvbfrd6e0v00&activetab=pivot%3Aoverviewtab) instead.

To be noted that if we hadn't used the default `unittest` folder name, we could have used the `-unittestFolder` parameter of `Install-AutToolset` to pass our specific value.

![figure 5 - Windows Terminal, installing the toolset screenshot](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/201912_asa_alm101/asa_alm105_iat.png)

*[figure 5 - Windows Terminal, installing the toolset screenshot](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/201912_asa_alm101/asa_alm105_iat.png)*

After all that we should be ready to do some testing.

## Local unit testing

First, we'll define 2 or 3 tests to run locally. If we take a look at the content of the `unittest\1_arrange` folder for inspiration, we'll see that a test case is made of input and output files named according to a convention. Let's not repeat [the full doc here](https://github.com/Fleid/asa.unittest#configuring-a-test-case) but instead build the following cases for the current query to be tested:

```SQL
SELECT
    deviceId,
    avg(temperature) as avg_temperature_t5,
    COUNT(*) as cnt_records_t5,
    System.Timestamp() AS EventAggregatedTime
INTO [BlobStorage1]
FROM [IoTHub1] TIMESTAMP BY EventProcessedUtcTime
GROUP BY deviceId, TumblingWindow(second,5)
```

We can use [live extracts](https://docs.microsoft.com/en-us/azure/stream-analytics/visual-studio-code-local-run#prepare-sample-data)  to generate test input data. For test output data, the best is to leverage the output files in the `LocalRunOutputs` folder, located in the ASA project after a successful local run. Note that these files may be generated in a line separated format which is not supported by the test runner, see the doc above on how to address that.

We can remove the files already in `unittest\1_assert`, as they are provided only to help us understand the naming conventions, and add the following 6 files instead:

- **001\~Input\~IoTHub1\~Nominal.json**

This is the nominal use case: 3 correct messages in, separated by more than 5 seconds to get 2 messages out (the query has a 5 second tumbling window).

```JSON
[
  {"messageId":225,"deviceId":"Raspberry Pi Web Client","temperature":28.836692209941976,"humidity":61.320061764993063,"EventProcessedUtcTime":"2019-11-09T05:55:09.9263983Z","PartitionId":0,"EventEnqueuedUtcTime":"2019-11-09T05:53:51.3740000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice001","ConnectionDeviceGenerationId":"637088714355240672","EnqueuedTime":"2019-11-09T05:53:51.0000000","StreamId":null}}
  ,
  {"messageId":228,"deviceId":"Raspberry Pi Web Client","temperature":27.794169792332852,"humidity":70.980360543970193,"EventProcessedUtcTime":"2019-11-09T05:55:10.9263983Z","PartitionId":0,"EventEnqueuedUtcTime":"2019-11-09T05:53:57.7540000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice001","ConnectionDeviceGenerationId":"637088714355240672","EnqueuedTime":"2019-11-09T05:53:57.0000000","StreamId":null}}
,
  {"messageId":229,"deviceId":"Raspberry Pi Web Client","temperature":29.567696660676628,"humidity":79.635582091098271,"EventProcessedUtcTime":"2019-11-09T05:55:12.9263983Z","PartitionId":0,"EventEnqueuedUtcTime":"2019-11-09T05:53:59.8960000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice001","ConnectionDeviceGenerationId":"637088714355240672","EnqueuedTime":"2019-11-09T05:53:59.0000000","StreamId":null}}
]
```

- **001\~Output\~BlobStorage1\~Nominal.json**

```JSON
[
     {"deviceId":"Raspberry Pi Web Client","avg_temperature_t5":28.836692209941976,"cnt_records_t5":1,"EventAggregatedTime":"2019-11-09T05:55:10.0000000Z"}
    ,{"deviceId":"Raspberry Pi Web Client","avg_temperature_t5":28.680933226504742,"cnt_records_t5":2,"EventAggregatedTime":"2019-11-09T05:55:15.0000000Z"}
]
```

- **002\~Input\~IoTHub1\~NullValue.json**

Highlighting only the differences from nominal: we set the temperature to null for message 229.

```JSON
[
  {"messageId":225,...}
  ,
  {"messageId":228,...}
,
  {"messageId":229,...,"temperature":null,...}
]
```

- **002\~Output\~BlobStorage1\~NullValue.json**

```JSON
[
     {"deviceId":"Raspberry Pi Web Client","avg_temperature_t5":28.836692209941976,"cnt_records_t5":1,"EventAggregatedTime":"2019-11-09T05:55:10.0000000Z"}
    ,{"deviceId":"Raspberry Pi Web Client","avg_temperature_t5":27.794169792332852,"cnt_records_t5":2,"EventAggregatedTime":"2019-11-09T05:55:15.0000000Z"}
]
```

- **003\~Input\~IoTHub1\~MissingValue.json**

Here we completely remove the `temperature` field from message 229 and check the impact.

- **003\~Output\~BlobStorage1\~MissingValue.json**

```JSON
[
     {"deviceId":"Raspberry Pi Web Client","avg_temperature_t5":28.836692209941976,"cnt_records_t5":1,"EventAggregatedTime":"2019-11-09T05:55:10.0000000Z"}
    ,{"deviceId":"Raspberry Pi Web Client","avg_temperature_t5":27.794169792332852,"cnt_records_t5":2,"EventAggregatedTime":"2019-11-09T05:55:15.0000000Z"}
]
```

Once this is set up, we can use the test runner to verify that when the query is applied on an input test set, it generates the expected output, matching the output provided. The test runner, `Start-AutRun.ps1`, will need the project name (`ASATest1` here), the solution folder path, but also an assert path - where to output the test results. By convention it should be set to `unittest\3_assert`.

In a PowerShell terminal, back in `unittest\2_act`:

```PowerShell
.\Start-AutRun.ps1 -asaProjectName ASATest1 -solutionPath "C:\Users\fleide\Repos\ASATest" -assertPath "C:\Users\fleide\Repos\ASATest\unittest\3_assert" -verbose
```

![figure 6 - Windows Terminal, successful test run](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/201912_asa_alm101/asa_alm105_localrun.png)

*[figure 6 - Windows Terminal, successful test run](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/201912_asa_alm101/asa_alm105_localrun.png)*

We can also have a look at the output folder (`\unittest\3_assert`) to see the details of the run.

Now is a good time to test messing with the query, or the input/output test files, to see how the test runner behave.

## Testing in the build pipeline

Unit tests should be run after compilation, during the build phase, to ensure the quality of the build.

In VSCode, we need to edit `build.ps1` so that it calls both the installer (`Install-AutToolset.ps1`) and the test runner (`Start-AutRun.ps1`) just after step 3:

```PowerShell
...

# Step 4: run unit tests

write-host "401 - Installing unit test dependencies"

$exe = "$sourceDirectory\$unittestFolder\2_act\Install-AutToolset.ps1"
& $exe -solutionPath $sourceDirectory -unittestFolder $unittestFolder -verbose

write-host "402 - Running unit tests"

$exe = "$sourceDirectory\$unittestFolder\2_act\Start-AutRun.ps1"
& $exe -asaProjectName $sourceProjectName -solutionPath $sourceDirectory -unittestFolder $unittestFolder -assertPath "$sourceDirectory\$unittestFolder\3_assert\" -verbose

# Step 5: move files to staging folder

write-host "501 - Moving release script to Staging Dir"
Move-item "$sourceDirectory\Deploy\release.ps1" $stagingDirectory

# Step 9 : done
write-host "999 - All done"
```

After committing and pushing to Azure DevOps, we'll have our unit tests running in our build pipeline:

![figure 7 - Azure DevOps Build Pipeline screenshot - failed job thanks to tests not passing](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/201912_asa_alm101/asa_alm105_failedtests.png)

*[figure 7 - Azure DevOps Build Pipeline screenshot - failed job thanks to tests not passing](https://raw.githubusercontent.com/Fleid/fleid.github.io/master/_posts/201912_asa_alm101/asa_alm105_failedtests.png)*

Above we can observe success in failure, as I intentionally left a failing test in my `1_assert` folder to check that my build would indeed fail.

## Success

> To do

## Next steps

- ~~Part 1~~ : [100 - The story of 2 pipelines](https://www.eiden.ca/asa-alm-100/)
- ~~Part 2~~ : [101 - Local developer experience](https://www.eiden.ca/asa-alm-101/)
- ~~Part 3~~ : [102 - Provisioning scripts and live job](https://www.eiden.ca/asa-alm-102/)
- ~~Part 4~~ : [103 - Continuous build](https://www.eiden.ca/asa-alm-103/)
- ~~Part 5~~ : [104 - Automated deployment](https://www.eiden.ca/asa-alm-104/)
- ~~Part 6~~ : [105 - Unit testing](https://www.eiden.ca/asa-alm-105/)
- Part 7 : Integration testing - to be written
