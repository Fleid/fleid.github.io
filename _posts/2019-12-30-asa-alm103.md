---
layout: post
title:  "Continuous build for an Azure Stream Analytics job - ALM 103 for ASA"
date:   2019-12-30 10:00:00 -0700
categories: ALM Azure ASA DevOps
---

# Build and Release pipelines for an Azure Stream Analytics job - ASA-ALM-103

This article is part of a series on enabling modern ALM practices for an Azure Stream Analytics project:

- Part 0 : [The story of 2 pipelines](https://www.eiden.ca/asa-alm-100/)
- Part 1 : [Developer experience](https://www.eiden.ca/asa-alm-101/)
- Part 2 : [Provisioning scripts](https://www.eiden.ca/asa-alm-102/)
- Part 3 : [Continuous build](https://www.eiden.ca/asa-alm-103/)
- Part 4 : Continuoys deployment - to be written
- Part 5 : Automated testing - to be written

## Context

Now that we have a job that can run live, with its data source and sink, we can start thinking [CI/CD](https://en.wikipedia.org/wiki/CI/CD).

For a bit of background:

**CI for Continuous Integration**, which starts with the practice of continuously building our application, every time the code is changed. Once continuous builds happen, we can decide to build at the master branch level, after changes are merged. When working as a team on a single scope of work, that will ensure that our entire code base is always in a happy place as we work collaboratively on it. Integration happens when we do that build in a production-like environment. Finally, to qualify for proper CI, we need to add automated testing. 

**CD for Continuous Deployment**, which is the practice of deploying our code to production automatically, once the CI has succedded (this is a bit more complicated than that, but let's go with that). 

To enable both practices, we'll need continuous builds on code changes, automated deployment on successful builds and automated testing (packaged unit tests in build, integration tests in deployment). This article will cover the first requirement.

Since we're already using **Azure DevOps** for repos, this will be done in [Azure Pipelines](https://docs.microsoft.com/en-us/azure/devops/pipelines/?view=azure-devops), in the **Build** section. Triggering our builds should be the `Git push`s we make to our central repository.

![Illustration of our dev pipeline](https://github.com/Fleid/fleid.github.io/blob/master/_posts/201912_asa_alm101/asa_alm103.png?raw=true)

If we were using Visual Studio (and not VSCode), there is [a tutorial](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-tools-visual-studio-cicd-vsts) in the official documentation on how to leverage a [certain nuget package](https://docs.microsoft.com/en-us/azure/stream-analytics/stream-analytics-tools-for-visual-studio-cicd) and `msbuild` to set up that pipeline. At the time of writing it was last edited in the summer of 2018. Let's try another way.

It is to be noted that I'm not an expert of **Azure DevOps**, so any [feedback](https://github.com/Fleid/fleid.github.io/blob/master/_posts/2019-12-30-asa-alm103.md) on how to do things in a more elegant way is appreciated.

## Build pipeline

In Azure DevOps, just under Repos we can find Pipelines. The first thing we'll create is a **new build pipeline**, linked to our Azure Repos repository. Let's go with YAML mode instead of the "classic editor". It may be a bit foreign at first, not having a UI to help, but that means our build definition will be a file that we can host in our repo. This is nice. Let's pick a **Starter Pipeline**, and we should be greated by something looking like that:

![Screenshot of the starter YAML pipeline](https://github.com/Fleid/fleid.github.io/blob/master/_posts/201912_asa_alm101/asa_alm103_build.png?raw=true)

We can save the YAML file back into our repo by clicking **Save** or **Save and run** (no real difference on a starter script). It should then be located in the root folder of the repo. To get it locally we should sync the repo back in VSCode. There the YAML file can be moved into our `deploy` folder, and we can push that change back to the repo. This should make the build pipeline unhappy (the TAML file can't be found anymore!). Which is easy to correct in the settings, under `YAML file path`:

![Screenshot of the starter YAML pipeline](https://github.com/Fleid/fleid.github.io/blob/master/_posts/201912_asa_alm101/asa_alm103_build_unhappy.png?raw=true)

Now let's take some time to think about what steps should go in there.

### Steps

The first thing that should happen in the build process is the generation of our ARM template files from our project assets. Right we have used VSCode to do that (```ASA: Compile scripts```), we will look into the [npm package](https://docs.microsoft.com/en-us/azure/stream-analytics/setup-cicd-vs-code) that allows to script that instead. 

Then we should validate those template, make sure they are correct - we have options to do just that ([PS](https://docs.microsoft.com/en-us/powershell/module/az.resources/test-azresourcegroupdeployment?view=azps-3.2.0), [CLI](https://docs.microsoft.com/en-us/cli/azure/group/deployment?view=azure-cli-latest#az-group-deployment-validate)).

Finally, we should publish those ARM template files to the release pipeline so they can be deployed against our staging environment.

Easy!

### ASA CI/CD npm package



### build.ps1

Let's start by thinking about why chosing PowerShell over CLI here.

### YAML

## Release pipeline

### Release steps

### Secrets

### release.ps1

Let's again think about why chosing PowerShell over CLI here.

## Next steps

- ~~Part 0~~ : [The story of 2 pipelines](https://www.eiden.ca/asa-alm-100/)
- ~~Part 1~~ : [Developer experience](https://www.eiden.ca/asa-alm-101/)
- ~~Part 2~~ : [Provisioning scripts](https://www.eiden.ca/asa-alm-102/)
- ~~Part 3~~ : [Continuous build](https://www.eiden.ca/asa-alm-103/)
- Part 4 : Continuoys deployment - to be written
- Part 5 : Automated testing - to be written
