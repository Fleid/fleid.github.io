---
layout: post
title:  "Automated deployment for an Azure Stream Analytics job - ASA-ALM-104"
date:   2020-01-07 10:00:00 -0700
categories: ALM Azure ASA DevOps
---

# Release pipeline for an Azure Stream Analytics job - ASA-ALM-104

This article is part of a series on enabling modern ALM practices for an Azure Stream Analytics project:

- Part 1 : [100 - The story of 2 pipelines](https://www.eiden.ca/asa-alm-100/)
- Part 2 : [101 - Local developer experience](https://www.eiden.ca/asa-alm-101/)
- Part 3 : [102 - Provisioning scripts and live job](https://www.eiden.ca/asa-alm-102/)
- Part 4 : [103 - Continuous build](https://www.eiden.ca/asa-alm-103/)
- **Part 5** : [104 - Automated deployment](https://www.eiden.ca/asa-alm-104/)
- Part 6 : Unit testing - to be written
- Part 7 : Integration testing - to be written

## Context

Now that we have a **continuous build pipeline** (see [103](https://www.eiden.ca/asa-alm-103/)) it should be easy to enable automated deployments using a **release pipeline** in Azure DevOps. 

For our project we will just deploy to one live environment: **staging**. Like we discussed [earlier](https://www.eiden.ca/asa-alm-100/), getting that wiring right will allow us to add [as many environments](https://docs.microsoft.com/en-us/azure/devops/pipelines/release/define-multistage-release-process?view=azure-devops) as we could want (staging, integration, UAT, pre-prod, prod...) later.

![Illustration of our dev pipeline](https://github.com/Fleid/fleid.github.io/blob/master/_posts/201912_asa_alm101/asa_alm103.png?raw=true)

## Release inputs

Deploying an ASA job via ARM templates will require the release pipeline to receive the **following inputs**:

- Where/how are we deploying - these are key details that we want to overload after the build
  - Target **resource group** and **ASA job name**. A good thing that we can rename our job at deployment to add its environment and potentially a version number in a suffix
  - **Location**, as in [Azure locations](https://azure.microsoft.com/en-us/global-infrastructure/locations/), or else the deployment will always end up being in the default location of the template (`Central US`). I haven't found a way to update that default value in the ASA project config file, not sure if I'm missing something
  - **OutputStartMode**, an attribute specific to ASA, its role being covered [in the doc](https://docs.microsoft.com/en-us/azure/stream-analytics/start-job). I haven't had the chance to play much with it and see how to leverage it to be smarter about restarts - if possible at all. Right now I default it to `LastOutputEventTime` which means "when last stopped" (of course the job needs to have run at least once for that to be available, we should run it manually once if necessary)
- The credentials/secrets of our **data** inputs and outputs:
  - If [for the build](https://www.eiden.ca/asa-alm-103/) we avoided loading the real credentials in our ARM template parameters file, now we will have too. Since we're doing things the right way, we'll store them in [KeyVault](https://azure.microsoft.com/en-us/services/key-vault/), and get them only when needed. 
  - We'll see how to do that below, but right now we need to know that a variable group (the way to share variables across pipelines in Azure DevOps) are either linked to KeyVault (all variables are loaded from KeyVault) or not. **So we'll need at least 2 variable groups**
- What we're deploying:
  - And of course, our **ARM template files** themselves, published by our build pipeline as *"Build Artifacts"*

![Focus on the release pipeline](https://github.com/Fleid/fleid.github.io/blob/master/_posts/201912_asa_alm101/asa_alm104_goal.png?raw=true)

Let's get started by covering those requirements.

## Infrastructure

As described above, we need a KeyVault and a couple of variable groups. Let's create that.

### KeyVault

The creation of the KeyVault, and management and its secrets, can be done via the [Azure portal](https://docs.microsoft.com/en-us/azure/key-vault/quick-create-portal), the [Azure CLI](https://docs.microsoft.com/en-us/azure/key-vault/quick-create-cli) or the [Azure PowerShell Az](https://docs.microsoft.com/en-us/azure/key-vault/quick-create-powershell) module.

Let's put that KeyVault in its own resource group, `rg-infra` for me, or at least the shared resource group, `rg-shared`, but not in the staging resource group, `rg-staging`. That way it will be more natural to reuse it and its secrets across environments and potentially projects (hello governance), and make it more durable - since the point of having a staging resource group is to be able to delete and recreate it at will.

Once created, we'll create the **secrets** we need, in this case:

- name: `kvinputIoTHub1key`, value: the key of the IoT Hub we're using as our live input
- name: `kvoutputBlobStorage1key`, value: the key of the storage account we're using as our live output

### Variable Groups

Back in Azure DevOps, let's go back to **Pipelines** > **Library** where [variable groups](https://docs.microsoft.com/en-us/azure/devops/pipelines/library/variable-groups?view=azure-devops&tabs=yaml) are managed.

We should already see the variable group we created [previously](https://www.eiden.ca/asa-alm-103/), hosting our resource group name variable (`StagingVariableGroup`). We can add the 3 additional variables required for release:

- name: `vg-ResourceGroup`, value: `rg-asateststaging`
- name: `vg-ASAJobNAme`,value: `MyStreamingJobstaging`
- name: `vg-Location`,value: `Canada Central`
- name: `vg-OutputStartMode`,value: `LastOutputEventTime`

Once this is done, we can create a new variable group, called `KeyVaultVariableGroup`. For this one we will enable *"Link secrets from an Azure keu vault as variables"* and reference our newly created KeyVault from above. Once this is done, we can add variables - which is just selecting which secrets from the KeyVault are going to be accessible.

We have our inputs, we can create our release pipeline.

## Release pipeline



### Steps

### deploy.ps1

## Success

A warning on CI/CD setups and 24/7 compute resources such as an ASA job: pushing code to the origin repository will re-start them. So remember to turn them back off, or unplug the pipeline if need be, or better - script it.

## Next steps

- ~~Part 1~~ : [100 - The story of 2 pipelines](https://www.eiden.ca/asa-alm-100/)
- ~~Part 2~~ : [101 - Local developer experience](https://www.eiden.ca/asa-alm-101/)
- ~~Part 3~~ : [102 - Provisioning scripts and live job](https://www.eiden.ca/asa-alm-102/)
- ~~Part 4~~ : [103 - Continuous build](https://www.eiden.ca/asa-alm-103/)
- ~~Part 5~~ : [104 - Automated deployment](https://www.eiden.ca/asa-alm-104/)
- Part 6 : Unit testing - to be written
- Part 7 : Integration testing - to be written
